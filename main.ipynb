{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aabdollahii/fine-tuning-a-gpt-2-model-for-a-custom-chatbot?scriptVersionId=265506448\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"b9f68cff","metadata":{"papermill":{"duration":0.00314,"end_time":"2025-10-03T14:35:09.159316","exception":false,"start_time":"2025-10-03T14:35:09.156176","status":"completed"},"tags":[]},"source":["<div style=\"background-color: #013220; color: #EAEAEA; border-radius: 15px; padding: 30px; font-family: 'Helvetica Neue', sans-serif; border: 1px solid #388E3C;\">\n","\n","<div style=\"text-align: center; font-size: 32px; font-weight: bold; color: #A5D6A7; padding-bottom: 15px; border-bottom: 2px solid #388E3C; margin-bottom: 25px;\">\n","        Fine-Tuning a GPT-2 Model for a Custom Chatbot\n","    </div>\n","\n","<div style=\"font-size: 20px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Project Overview\n","    </div>\n","    <div style=\"font-size: 16px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        Welcome to this hands-on guide to fine-tuning a Large Language Model (LLM)! In this project, we will transform a general-purpose language model, the powerful GPT-2, into a specialized chatbot. Our goal is to leverage a dataset of 3,000 conversational pairs to teach the model a specific conversational style and knowledge base. This process, known as fine-tuning, is a cornerstone of modern NLP, allowing us to adapt massive pre-trained models for specific tasks without the prohibitive cost of training them from scratch. By the end of this notebook, you will have a functional chatbot customized with our data and a clear understanding of the end-to-end LLM fine-tuning workflow.\n","    </div>\n","\n","<div style=\"font-size: 20px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        The Core Objective\n","    </div>\n","    <div style=\"font-size: 16px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        Our primary objective is to demonstrate the power of transfer learning in NLP. We will take the `distilgpt2` modelâ€”a smaller, faster variant of GPT-2 that is perfect for experimentation in environments like Kaggleâ€”and train it further on a custom question-and-answer dataset. We will then compare the responses of the original, base model with our newly fine-tuned model to concretely measure the improvement and see how the model's personality and knowledge have shifted.\n","    </div>\n","\n"," <div style=\"font-size: 20px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Methodology at a Glance\n","    </div>\n","    <div style=\"font-size: 16px; line-height: 1.7; text-align: justify;\">\n","        Our approach is structured into a clear, step-by-step process:\n","        <div style=\"margin-top: 15px; padding-left: 20px;\">\n","            <div style=\"margin-bottom: 10px;\"><b>1. Environment Setup:</b> We will import essential libraries like PyTorch and Hugging Face's `transformers` and `datasets`.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>2. Data Loading & Preparation:</b> We will load the 3k conversations dataset and format it into a single text sequence per conversation, making it suitable for training a causal language model like GPT-2.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>3. Model & Tokenizer Initialization:</b> We will load the pre-trained `distilgpt2` model and its corresponding tokenizer, setting up the necessary configurations for training.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>4. Fine-Tuning:</b> Using the Hugging Face `Trainer` API, we will fine-tune the model on our prepared dataset. This is where the model learns the new conversational patterns.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>5. Inference & Evaluation:</b> Finally, we'll test our new chatbot! We will provide it with prompts and compare its generated answers against those from the original model to see our improvements in action.</div>\n","        </div>\n","    </div>\n","\n","</div>\n"]},{"cell_type":"markdown","id":"cf6df4ac","metadata":{"papermill":{"duration":0.001986,"end_time":"2025-10-03T14:35:09.164041","exception":false,"start_time":"2025-10-03T14:35:09.162055","status":"completed"},"tags":[]},"source":["<div style=\"background-color: #013220; color: #EAEAEA; border-radius: 15px; padding: 30px; font-family: 'Helvetica Neue', sans-serif; border: 1px solid #388E3C;\">\n","\n"," <div style=\"text-align: center; font-size: 28px; font-weight: bold; color: #A5D6A7; padding-bottom: 15px; border-bottom: 2px solid #388E3C; margin-bottom: 25px;\">\n","        Step 2: Environment Setup & Loading the Base Model/Tokenizer\n","    </div>\n","\n"," <div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Objective of This Step\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        In this step, we prepare our Kaggle environment for working with Large Language Models using the Hugging Face <code>transformers</code> library alongside <code>PyTorch</code>. This includes installing any required dependencies, importing essential packages, and initializing the building blocks of our project â€” the pre-trained base model and its tokenizer.\n","        The tokenizer is responsible for converting human-readable text into a sequence of tokens (numerical IDs) that the model can understand, while the model itself is the neural network that processes those tokens to generate text predictions.\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Why We Use DistilGPT-2\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        We will use <code>distilgpt2</code>, which is a distilled (smaller and faster) version of GPT-2. This choice allows us to train and experiment quickly in Kaggle's GPU environment without exhausting memory or exceeding time limits, while still benefiting from the rich language understanding learned during GPT-2's original training.\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Actions We Will Perform\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify;\">\n","        <div style=\"padding-left: 20px;\">\n","            <div style=\"margin-bottom: 10px;\"><b>1.</b> Import the necessary Python packages: <code>transformers</code>, <code>torch</code>, and optionally <code>datasets</code>.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>2.</b> Initialize the model <code>distilgpt2</code> using the Hugging Face model hub.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>3.</b> Load the corresponding tokenizer so we can transform raw text into token IDs for the model to process.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>4.</b> Verify that the model and tokenizer are ready for fine-tuning on our custom dataset in the next steps.</div>\n","        </div>\n","    </div>\n","\n","</div>\n"]},{"cell_type":"code","execution_count":1,"id":"8fa04279","metadata":{"execution":{"iopub.execute_input":"2025-10-03T14:35:09.169611Z","iopub.status.busy":"2025-10-03T14:35:09.169362Z","iopub.status.idle":"2025-10-03T14:35:41.626643Z","shell.execute_reply":"2025-10-03T14:35:41.625632Z"},"papermill":{"duration":32.461868,"end_time":"2025-10-03T14:35:41.628083","exception":false,"start_time":"2025-10-03T14:35:09.166215","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce55a5a13594453aad44f664099dd930","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e83f9b7a0304f78b5ba679aa7aeb5d9","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2ba11375af640aca76e2a7f408d55eb","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48a114953fbe44ea97880d6301da7cc6","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7225b7b5aae4417a92c9358c4d27e05f","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["2025-10-03 14:35:26.683570: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1759502126.866302      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1759502126.918122      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"831b268a2c714159b6078e086c08c066","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"503e667ac7324afca0e0b62a69942ecc","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Sample token IDs: tensor([[15496,    11,   703,   389,   345,    30]], device='cuda:0')\n"]}],"source":["\n","\n","# Install the Hugging Face Transformers library (if not already available in Kaggle)\n","#!pip install transformers datasets --quiet\n","\n","# Import required libraries\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# Load the tokenizer for distilgpt2\n","tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n","\n","# Load the base model (DistilGPT-2) for Causal Language Modeling\n","model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\").to(device)\n","\n","# Verify model and tokenizer are ready\n","sample_text = \"Hello, how are you?\"\n","encoded_input = tokenizer.encode(sample_text, return_tensors=\"pt\").to(device)\n","print(\"Sample token IDs:\", encoded_input)\n"]},{"cell_type":"code","execution_count":2,"id":"eb119d3f","metadata":{"execution":{"iopub.execute_input":"2025-10-03T14:35:41.635673Z","iopub.status.busy":"2025-10-03T14:35:41.635208Z","iopub.status.idle":"2025-10-03T14:35:41.702044Z","shell.execute_reply":"2025-10-03T14:35:41.701053Z"},"papermill":{"duration":0.071871,"end_time":"2025-10-03T14:35:41.703301","exception":false,"start_time":"2025-10-03T14:35:41.63143","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset Shape: (3725, 3)\n","\n","Column Names: ['Unnamed: 0', 'question', 'answer']\n","\n","Sample Rows:\n","   Unnamed: 0                             question  \\\n","0           0               hi, how are you doing?   \n","1           1        i'm fine. how about yourself?   \n","2           2  i'm pretty good. thanks for asking.   \n","3           3    no problem. so how have you been?   \n","4           4     i've been great. what about you?   \n","\n","                                     answer  \n","0             i'm fine. how about yourself?  \n","1       i'm pretty good. thanks for asking.  \n","2         no problem. so how have you been?  \n","3          i've been great. what about you?  \n","4  i've been good. i'm in school right now.  \n","\n","Missing Values Per Column:\n","Unnamed: 0    0\n","question      0\n","answer        0\n","dtype: int64\n","\n","Dataset Statistics:\n","         Unnamed: 0           question             answer\n","count   3725.000000               3725               3725\n","unique          NaN               3510               3512\n","top             NaN  what do you mean?  what do you mean?\n","freq            NaN                 22                 22\n","mean    1862.000000                NaN                NaN\n","std     1075.459204                NaN                NaN\n","min        0.000000                NaN                NaN\n","25%      931.000000                NaN                NaN\n","50%     1862.000000                NaN                NaN\n","75%     2793.000000                NaN                NaN\n","max     3724.000000                NaN                NaN\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n","  has_large_values = (abs_vals > 1e6).any()\n","/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n","  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n","  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n"]}],"source":["import pandas as pd\n","\n","# Dataset path in Kaggle\n","dataset_path = \"/kaggle/input/3k-conversations-dataset-for-chatbot/Conversation.csv\"\n","\n","# Load CSV file into a Pandas DataFrame\n","df = pd.read_csv(dataset_path)\n","\n","# Show basic info about the dataset\n","print(\"Dataset Shape:\", df.shape)\n","print(\"\\nColumn Names:\", df.columns.tolist())\n","\n","# Display first few rows\n","print(\"\\nSample Rows:\")\n","print(df.head())\n","\n","# Check for missing values\n","print(\"\\nMissing Values Per Column:\")\n","print(df.isnull().sum())\n","\n","# Show basic statistics (if numerical columns exist)\n","print(\"\\nDataset Statistics:\")\n","print(df.describe(include='all'))\n"]},{"cell_type":"markdown","id":"1de339e8","metadata":{"papermill":{"duration":0.003047,"end_time":"2025-10-03T14:35:41.710233","exception":false,"start_time":"2025-10-03T14:35:41.707186","status":"completed"},"tags":[]},"source":["<div style=\"background-color: #013220; color: #EAEAEA; border-radius: 15px; padding: 30px; font-family: 'Helvetica Neue', sans-serif; border: 1px solid #388E3C;\">\n","\n","<div style=\"text-align: center; font-size: 28px; font-weight: bold; color: #A5D6A7; padding-bottom: 15px; border-bottom: 2px solid #388E3C; margin-bottom: 25px;\">\n","        Step 3: Data Preparation for Fine-Tuning\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Objective of This Step\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        The core objective here is to transform our structured dataset (with 'question' and 'answer' columns) into a format suitable for training a causal language model. GPT-2 learns by predicting the next token in a continuous sequence of text. Our current two-column format isn't a continuous sequence, so we must combine them into one. We will create a single text string for each row that clearly represents the conversational flow.\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Our Formatting Strategy\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        To help the model learn the structure of a conversation, we will format each row into a single string like this:\n","        <br><br>\n","        <code>\"&lt;s&gt;[Q]: How are you? [A]: I'm doing great, thanks!&lt;/s&gt;\"</code>\n","        <br><br>\n","        Here, <code>&lt;s&gt;</code> and <code>&lt;/s&gt;</code> represent the <b>start</b> and <b>end</b> of a single conversational exchange. This special token (known as the EOS or End-of-Sequence token) is crucial because it teaches the model when a thought or response is complete, which is vital for generating coherent answers during inference.\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Actions We Will Perform\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify;\">\n","        <div style=\"padding-left: 20px;\">\n","            <div style=\"margin-bottom: 10px;\"><b>1. Combine Columns:</b> We will merge the 'question' and 'answer' columns into a new column, applying our formatting rule.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>2. Configure Tokenizer:</b> Since <code>distilgpt2</code> does not have a default padding token, we will set its padding token to be the same as its end-of-sequence (EOS) token. This is a standard practice for this model.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>3. Create a Dataset Object:</b> We will convert our Pandas DataFrame into a Hugging Face <code>Dataset</code> object for efficient processing and tokenization.</div>\n","        </div>\n","    </div>\n","\n","</div>\n"]},{"cell_type":"code","execution_count":3,"id":"7aa2855e","metadata":{"execution":{"iopub.execute_input":"2025-10-03T14:35:41.718164Z","iopub.status.busy":"2025-10-03T14:35:41.717465Z","iopub.status.idle":"2025-10-03T14:35:42.753522Z","shell.execute_reply":"2025-10-03T14:35:42.752836Z"},"papermill":{"duration":1.041817,"end_time":"2025-10-03T14:35:42.755196","exception":false,"start_time":"2025-10-03T14:35:41.713379","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample of formatted data:\n","0    <s>[Q]: hi, how are you doing? [A]: i'm fine. ...\n","1    <s>[Q]: i'm fine. how about yourself? [A]: i'm...\n","2    <s>[Q]: i'm pretty good. thanks for asking. [A...\n","3    <s>[Q]: no problem. so how have you been? [A]:...\n","4    <s>[Q]: i've been great. what about you? [A]: ...\n","Name: text, dtype: object\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cda416a18dae47918ab902682c06c783","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3725 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Dataset has been processed and tokenized.\n","A single example from the tokenized dataset:\n","{'input_ids': [27, 82, 36937, 48, 5974, 23105, 11, 703, 389, 345, 1804, 30, 685, 32, 5974, 1312, 1101, 3734, 13, 703, 546, 3511, 30, 3556, 82, 29, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"]}],"source":["# Step 3: Data Preparation for Fine-Tuning\n","\n","\n","\n","from datasets import Dataset\n","\n","# --- 1. Format the data into a single string per row ---\n","# We will format our data as \"<s>[Q]: {question} [A]: {answer}</s>\"\n","# <s> and </s> are special tokens that mark the start and end of a sequence.\n","# This helps the model understand the structure of a complete conversational turn.\n","\n","def format_conversation(row):\n","    return f\"<s>[Q]: {row['question']} [A]: {row['answer']}</s>\"\n","\n","# Apply the formatting to the DataFrame\n","df['text'] = df.apply(format_conversation, axis=1)\n","\n","print(\"Sample of formatted data:\")\n","print(df['text'].head())\n","\n","\n","# --- 2. Configure the tokenizer ---\n","# The distilgpt2 model doesn't have a default padding token.\n","# We'll use the end-of-sequence (EOS) token as our padding token.\n","# This is a common practice for GPT-style models.\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","\n","# --- 3. Create a Hugging Face Dataset object ---\n","# The Hugging Face Trainer API works best with 'Dataset' objects.\n","# We will convert our formatted text column from the pandas DataFrame\n","# into this specialized format.\n","\n","# First, create a new DataFrame with only the text we need\n","training_data = pd.DataFrame({'text': df['text']})\n","\n","# Convert the pandas DataFrame to a Hugging Face Dataset\n","dataset = Dataset.from_pandas(training_data)\n","\n","# --- 4. Tokenize the entire dataset ---\n","# We'll apply the tokenizer to all our text examples. The tokenizer will\n","# convert the text into numerical IDs that the model can understand.\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n","\n","print(\"\\nDataset has been processed and tokenized.\")\n","print(\"A single example from the tokenized dataset:\")\n","print(tokenized_dataset[0])\n"]},{"cell_type":"markdown","id":"844f6fb2","metadata":{"papermill":{"duration":0.003834,"end_time":"2025-10-03T14:35:42.768518","exception":false,"start_time":"2025-10-03T14:35:42.764684","status":"completed"},"tags":[]},"source":["<div style=\"background-color: #013220; color: #EAEAEA; border-radius: 15px; padding: 30px; font-family: 'Helvetica Neue', sans-serif; border: 1px solid #388E3C;\">\n","\n"," <div style=\"text-align: center; font-size: 28px; font-weight: bold; color: #A5D6A7; padding-bottom: 15px; border-bottom: 2px solid #388E3C; margin-bottom: 25px;\">\n","        Step 4: Fine-Tuning the Language Model\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Objective of This Step\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        This is the core of our project. We will now take the pre-trained <code>distilgpt2</code> model and train it further on our specially prepared conversational dataset. This process, known as fine-tuning, adjusts the model's internal weights to specialize its knowledge and conversational style to match our data. To manage the complexities of a training loop (like batching data, calculating loss, and updating model weights), we will use the high-level <code>Trainer</code> API from the Hugging Face library, which simplifies the entire process immensely.\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Key Components: `TrainingArguments` and `Trainer`\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        The <code>Trainer</code> API requires two main components:\n","        <br><br>\n","        1. <b><code>TrainingArguments</code></b>: This is a configuration class where we define all the hyperparameters for our training run. This includes the number of epochs (how many times to go through the data), the batch size, the learning rate, and where to save the trained model.\n","        <br><br>\n","        2. <b><code>Trainer</code></b>: This is the main class that orchestrates the training. We simply provide it with our model, the training arguments, and our tokenized dataset. It handles the entire training loop automatically.\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Actions We Will Perform\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify;\">\n","        <div style=\"padding-left: 20px;\">\n","            <div style=\"margin-bottom: 10px;\"><b>1. Define Training Arguments:</b> We'll set up the training configuration, choosing parameters that are well-suited for a Kaggle environment.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>2. Instantiate the Trainer:</b> We will create an instance of the <code>Trainer</code>, passing it our model, dataset, and arguments.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>3. Launch Training:</b> We will call the <code>.train()</code> method to start the fine-tuning process. You will see the training loss decrease over time, indicating that the model is learning.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>4. Save the Final Model:</b> Once training is complete, we will save our newly fine-tuned model to a directory so we can use it for inference in the next step.</div>\n","        </div>\n","    </div>\n","\n","</div>\n"]},{"cell_type":"code","execution_count":4,"id":"0c57fdab","metadata":{"execution":{"iopub.execute_input":"2025-10-03T14:35:42.77623Z","iopub.status.busy":"2025-10-03T14:35:42.775725Z","iopub.status.idle":"2025-10-03T14:37:01.467925Z","shell.execute_reply":"2025-10-03T14:37:01.467068Z"},"papermill":{"duration":78.697536,"end_time":"2025-10-03T14:37:01.469341","exception":false,"start_time":"2025-10-03T14:35:42.771805","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting the fine-tuning process...\n"]},{"name":"stderr","output_type":"stream","text":["`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='932' max='932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [932/932 01:14, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>1.120900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fine-tuning complete.\n","\n","Model and tokenizer have been saved to './chatbot_model'\n"]}],"source":["# ===============================================\n","# Step 4: Fine-Tuning the Model (Corrected Code)\n","# ===============================================\n","\n","from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n","\n","# --- 1. Define Training Arguments ---\n","# (This part remains exactly the same)\n","training_args = TrainingArguments(\n","    output_dir=\"./chatbot_model\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=2,\n","    warmup_steps=100,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=500,\n","    save_strategy=\"epoch\",\n","    report_to=\"none\"\n",")\n","\n","# --- 2. Create the Data Collator ---\n","# This collator will automatically create the 'labels' needed for the loss calculation.\n","# For GPT-2 style models (Causal LM), we set mlm=False.\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, \n","    mlm=False\n",")\n","\n","# --- 3. Instantiate the Trainer ---\n","# We now add the data_collator to the Trainer.\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    data_collator=data_collator,  # <-- This is the new key argument\n",")\n","\n","# --- 4. Launch Training ---\n","print(\"Starting the fine-tuning process...\")\n","trainer.train()\n","print(\"Fine-tuning complete.\")\n","\n","# --- 5. Save the Final Model and Tokenizer ---\n","trainer.save_model(\"./chatbot_model\")\n","tokenizer.save_pretrained(\"./chatbot_model\")\n","\n","print(\"\\nModel and tokenizer have been saved to './chatbot_model'\")\n"]},{"cell_type":"markdown","id":"04ae794e","metadata":{"papermill":{"duration":0.003704,"end_time":"2025-10-03T14:37:01.478304","exception":false,"start_time":"2025-10-03T14:37:01.4746","status":"completed"},"tags":[]},"source":["<div style=\"background-color: #013220; color: #EAEAEA; border-radius: 15px; padding: 30px; font-family: 'Helvetica Neue', sans-serif; border: 1px solid #388E3C;\">\n","\n","<div style=\"text-align: center; font-size: 28px; font-weight: bold; color: #A5D6A7; padding-bottom: 15px; border-bottom: 2px solid #388E3C; margin-bottom: 25px;\">\n","        Step 5: Inference with the Fine-Tuned Chatbot Model\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Objective of This Step\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify; margin-bottom: 20px;\">\n","        In this step, we load our fine-tuned GPT-2 variant (<code>distilgpt2</code>) from the <code>./chatbot_model</code> directory and use it to generate chatbot responses to custom prompts. We will leverage the Hugging Face <code>generate()</code> method to produce coherent, context-aware text that reflects the conversational style learned during fine-tuning.\n","    </div>\n","\n","<div style=\"font-size: 18px; font-weight: bold; color: #81C784; margin-top: 25px; margin-bottom: 10px;\">\n","        Key Actions to Perform\n","    </div>\n","    <div style=\"font-size: 15px; line-height: 1.7; text-align: justify;\">\n","        <div style=\"padding-left: 20px;\">\n","            <div style=\"margin-bottom: 10px;\"><b>1.</b> Load the saved model and tokenizer from <code>./chatbot_model</code>.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>2.</b> Prepare a sample prompt that simulates a chatbot conversation (e.g., <code>[Q]: How are you today?</code>).</div>\n","            <div style=\"margin-bottom: 10px;\"><b>3.</b> Tokenize the prompt and pass it to the model's <code>generate()</code> function to produce a continuation.</div>\n","            <div style=\"margin-bottom: 10px;\"><b>4.</b> Decode the generated tokens back into text for human-readable output.</div>\n","        </div>\n","    </div>\n","\n","</div>\n"]},{"cell_type":"code","execution_count":5,"id":"ff0be919","metadata":{"execution":{"iopub.execute_input":"2025-10-03T14:37:01.487523Z","iopub.status.busy":"2025-10-03T14:37:01.487208Z","iopub.status.idle":"2025-10-03T14:37:07.068127Z","shell.execute_reply":"2025-10-03T14:37:07.06717Z"},"papermill":{"duration":5.58733,"end_time":"2025-10-03T14:37:07.069501","exception":false,"start_time":"2025-10-03T14:37:01.482171","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Starting Batch Inference ---\n","\n","[Q]: How are you today?\n","[Bot]: i'm in the middle of a busy day.)\n","\n","\n","\n","\n","\n","[A]: i'm so tired.\n","\n","\n","\n","\n","\n","\n","\n","<|endoftext|>\n","\n","[Q]: what is your name?\n","[Bot]: i'm from the Philippines, so i'm from the Philippines.)\n","\n","[Q]: Do you feel Good?\n","[Bot]: yes, i feel good.</Q]: so, what do you mean?</Q]: i feel bad.</Q]: i have to thank you.\n","\n","\n","\n","\n","<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n","\n","\n","</script>\n","\n","\n","<|endoftext|>\n","\n","--- Batch Inference Finished ---\n"]}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","import re\n","\n","# 1. Load fine-tuned model & tokenizer\n","model_path = \"./chatbot_model\" \n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","model = AutoModelForCausalLM.from_pretrained(model_path)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Helper function: Clean model output from special sequences\n","def clean_response(text, prompt):\n","    \"\"\"\n","    This function removes the original prompt and special tokens \n","    from the generated text.\n","    \"\"\"\n","    # Remove the original prompt part\n","    reply = text[len(prompt):]\n","    # Strip GPT special format tags and extra spaces\n","    reply = re.sub(r\"<s>|</s>\", \"\", reply)\n","    return reply.strip()\n","\n","# 2. Define a list of questions to ask the bot\n","questions = [\n","    \"How are you today?\",\n","    \"what is your name?\",\n","    \"Do you feel Good?\"\n","]\n","\n","print(\"--- Starting Batch Inference ---\")\n","\n","# 3. Loop through the predefined questions and get answers\n","for user_q in questions:\n","    print(f\"\\n[Q]: {user_q}\")\n","    \n","    # Format the prompt\n","    prompt = f\"[Q]: {user_q} [A]:\"\n","    \n","    # Tokenize the input\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","    \n","    # Generate a response from the model\n","    \n","    output_ids = model.generate(\n","        **inputs,\n","        max_length=100,\n","        temperature=0.7,\n","        top_k=50,\n","        top_p=0.95,\n","        do_sample=True,\n","        pad_token_id=tokenizer.eos_token_id,\n","        eos_token_id=tokenizer.eos_token_id\n","    )\n","    \n","    # Decode the generated token IDs back to a string\n","    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=False) # Keep special tokens for cleaning\n","    \n","    # Clean the response to show only the bot's answer\n","    reply = clean_response(generated_text, prompt)\n","    \n","    print(f\"[Bot]: {reply}\")\n","\n","print(\"\\n--- Batch Inference Finished ---\")\n"]},{"cell_type":"markdown","id":"5a8b75b7","metadata":{"papermill":{"duration":0.003776,"end_time":"2025-10-03T14:37:07.077451","exception":false,"start_time":"2025-10-03T14:37:07.073675","status":"completed"},"tags":[]},"source":["<div style=\"background-color:#121212; color:#f0f0f0; padding:20px; border-radius:10px; font-family:Arial, sans-serif; font-size:15px;\">\n","    <h2 style=\"color:#77dd77;\">ðŸ“Œ Chatbot Batch Inference (Nonâ€‘Interactive)</h2>\n","    <p>\n","        This notebook runs a <b>fineâ€‘tuned Transformer chatbot model</b> in a \n","        <span style=\"color:#add8e6;\">non-interactive batch mode</span> so it can execute on Kaggle without requiring \n","        <code>input()</code> from the user.  \n","        We define a <span style=\"color:#add8e6;\">list of preâ€‘written questions</span> and the model generates responses for each in sequence.\n","    </p>\n","    <p style=\"color:#ffcccb;\">\n","        âš  Note: Model outputs may <b>sometimes be inaccurate or incomplete</b> because the dataset used for training \n","        was not very large or heavy. Limited data can reduce generalization quality.\n","    </p>\n","    <h3 style=\"color:#f0e68c;\">Key Features:</h3>\n","    <ul>\n","        <li>âœ” Preâ€‘defined questions list for automatic execution</li>\n","        <li>âœ” Custom prompt formatting (<code>[Q]: ... [A]:</code>)</li>\n","        <li>âœ” Response cleaning to remove special tokens</li>\n","        <li>âœ” Tunable generation parameters (<code>temperature</code>, <code>top_k</code>, <code>top_p</code>)</li>\n","    </ul>\n","</div>\n"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":2958426,"sourceId":5094410,"sourceType":"datasetVersion"}],"dockerImageVersionId":31089,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"papermill":{"default_parameters":{},"duration":125.277927,"end_time":"2025-10-03T14:37:10.264094","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-10-03T14:35:04.986167","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"012a4c00b9db40489cb7795103b32546":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"035169b3c2a94a91a5dd366577a2d45a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_39277adb90634ef799569516f2472888","max":456318.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_b9c9b2960739404c939f18ad4b38554f","tabbable":null,"tooltip":null,"value":456318.0}},"05f242409a2b434e98874122ddf6e663":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"069d921009c94e10b0814b81a58f3548":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06d4488676ff4d2b8a711c5cca62b00c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0762539edd78430caacae16a3bf209d7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"07dee66b436641c9bee06ea2c8bc8ff3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"085557d00f8440e7a2c84b955951f1e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_07dee66b436641c9bee06ea2c8bc8ff3","max":3725.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_a0bcb1299987460f8887dfb874d903c6","tabbable":null,"tooltip":null,"value":3725.0}},"0b5e2933d14b4a8fb1e789c38337e748":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d5f16d2b36947968ee4b3805ec3fe38":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_45d09c1835ac44ec8fd2231891c2226a","placeholder":"â€‹","style":"IPY_MODEL_ca7ef867528a4890b960d8cf1f1ed12e","tabbable":null,"tooltip":null,"value":"â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡22.9MB/s]"}},"0e83f9b7a0304f78b5ba679aa7aeb5d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3c263027017a4581b65b214feb316578","IPY_MODEL_44c08e3ecb414d27bf2f112ca940ac0d","IPY_MODEL_c5c6c96627454513aa70ab1fdac98207"],"layout":"IPY_MODEL_217ea292c7c74a3e81ac54eb2099bb3e","tabbable":null,"tooltip":null}},"0f6f8d7af4634d48b17ec70e3b605d04":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_7720cd0743f440b68219c2b4c30f4241","placeholder":"â€‹","style":"IPY_MODEL_f603b22778664b14a7e6dfdd1bfeb160","tabbable":null,"tooltip":null,"value":"tokenizer.json:â€‡100%"}},"108117f490b0487ca287f4f82430b904":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17208e9c8548494b9d5d1efc611d3e06":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_06d4488676ff4d2b8a711c5cca62b00c","max":1042301.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_91cae49f4817468db7a5e3195ebe3385","tabbable":null,"tooltip":null,"value":1042301.0}},"217ea292c7c74a3e81ac54eb2099bb3e":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28b73a1708474add8399168a57baf958":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"29d9933bcb9147269c85627bfd833d4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"37a5357fd6c34574b7361e962c17d2a5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39277adb90634ef799569516f2472888":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c263027017a4581b65b214feb316578":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e56d0554274a4121a02d71b604ae2a6d","placeholder":"â€‹","style":"IPY_MODEL_ec93d80a857944f98f0dfe4ea90325bc","tabbable":null,"tooltip":null,"value":"config.json:â€‡100%"}},"3edebc19685841bf9467ec4213803d06":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"3f94719ac38a4bc68195079da4afa167":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"44c08e3ecb414d27bf2f112ca940ac0d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_f613418f2a9f48c2a22b4e2c45d88fe6","max":762.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_e30ee52cc7cd4b8e95b0b8b1d03a923e","tabbable":null,"tooltip":null,"value":762.0}},"45d09c1835ac44ec8fd2231891c2226a":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48973c20781f4dffa2269edd41565276":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_069d921009c94e10b0814b81a58f3548","placeholder":"â€‹","style":"IPY_MODEL_73f3d50908294ea1bd42daa9d961b88d","tabbable":null,"tooltip":null,"value":"â€‡1.04M/1.04Mâ€‡[00:00&lt;00:00,â€‡9.14MB/s]"}},"48a114953fbe44ea97880d6301da7cc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c894cd9ae324609b1e34efbb6c84499","IPY_MODEL_035169b3c2a94a91a5dd366577a2d45a","IPY_MODEL_c55b7d411bc54a2587425ef7d726ce86"],"layout":"IPY_MODEL_ea41480edab142d2a6e91c5030353824","tabbable":null,"tooltip":null}},"4d102158419a463eb9e3d01aa2d68bd9":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"503e667ac7324afca0e0b62a69942ecc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7c24fdfd272b486a9fda64e60ef3ed1b","IPY_MODEL_6312aa48719647498ae597a2157519b2","IPY_MODEL_c4450346f0c748cea5ea485e16740fa2"],"layout":"IPY_MODEL_a1ecbf82f60645029c66b7b0cfd4c2e0","tabbable":null,"tooltip":null}},"518ce5584fbb4a9ca2b674a730020d54":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54600c82f4454ffabd10110f8dc414af":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_d787eb4d0cbf478d87634d0a911a08d5","placeholder":"â€‹","style":"IPY_MODEL_6452a129527b47659989b1be2d49935f","tabbable":null,"tooltip":null,"value":"model.safetensors:â€‡100%"}},"5a87bd97cec74f989fb01c7511192290":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c1788efbd8546779aed1a3f52b64045":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_efb68158971745e9a02d38c5145bc996","placeholder":"â€‹","style":"IPY_MODEL_d89b44c9422c49cf93df18cfc3608d12","tabbable":null,"tooltip":null,"value":"â€‡26.0/26.0â€‡[00:00&lt;00:00,â€‡2.58kB/s]"}},"5d92609e280946a3ac851d0d5e7e4e11":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"61858c3380bf46089f823bdc4619c1c5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6312aa48719647498ae597a2157519b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_d54680151dea4a89a5edc6426875ebbd","max":124.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_db995b43df7f43b4a4644b17a3864c40","tabbable":null,"tooltip":null,"value":124.0}},"6452a129527b47659989b1be2d49935f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"69e568c7a7154f45967603933983cb0c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7225b7b5aae4417a92c9358c4d27e05f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0f6f8d7af4634d48b17ec70e3b605d04","IPY_MODEL_b401b898816d455db5cdb11889996c54","IPY_MODEL_0d5f16d2b36947968ee4b3805ec3fe38"],"layout":"IPY_MODEL_05f242409a2b434e98874122ddf6e663","tabbable":null,"tooltip":null}},"72baa150c0da4a42b0463ec5c31731d5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73f3d50908294ea1bd42daa9d961b88d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"75204fcfac51470ea43cf0085e9389a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_108117f490b0487ca287f4f82430b904","placeholder":"â€‹","style":"IPY_MODEL_29d9933bcb9147269c85627bfd833d4b","tabbable":null,"tooltip":null,"value":"Map:â€‡100%"}},"752ab28e2da44283a335f94843c07da0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7720cd0743f440b68219c2b4c30f4241":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c24fdfd272b486a9fda64e60ef3ed1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_61858c3380bf46089f823bdc4619c1c5","placeholder":"â€‹","style":"IPY_MODEL_5d92609e280946a3ac851d0d5e7e4e11","tabbable":null,"tooltip":null,"value":"generation_config.json:â€‡100%"}},"7c894cd9ae324609b1e34efbb6c84499":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_be0d810060e54fc38ed15c2dce79bec5","placeholder":"â€‹","style":"IPY_MODEL_012a4c00b9db40489cb7795103b32546","tabbable":null,"tooltip":null,"value":"merges.txt:â€‡100%"}},"7d26c1c69f6843a7bca8eff45b301330":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"831b268a2c714159b6078e086c08c066":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54600c82f4454ffabd10110f8dc414af","IPY_MODEL_fd294cfc69b6401d8badb78d25d54166","IPY_MODEL_f9b58c66b18646d3a48227b93cd6f685"],"layout":"IPY_MODEL_72baa150c0da4a42b0463ec5c31731d5","tabbable":null,"tooltip":null}},"8aedd556af1d41f985441deeaec97292":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fb958e31d6843239c9a7f0b48b10936":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91cae49f4817468db7a5e3195ebe3385":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"91f17b63ec784a0a980de540afce6209":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93978351af064af0a43bf171f3c98c5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0bcb1299987460f8887dfb874d903c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a1ecbf82f60645029c66b7b0cfd4c2e0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a78b81c47e9a43c18df9d0d3b55bcc22":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"add0878bd0a742fa882bad3d1e5512fb":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea3325eb678447ca8b9b607fc6fe982":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_0b5e2933d14b4a8fb1e789c38337e748","max":26.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_4d102158419a463eb9e3d01aa2d68bd9","tabbable":null,"tooltip":null,"value":26.0}},"b401b898816d455db5cdb11889996c54":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_69e568c7a7154f45967603933983cb0c","max":1355256.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_93978351af064af0a43bf171f3c98c5f","tabbable":null,"tooltip":null,"value":1355256.0}},"b5fcbe242e1b4bfe92919b11c1b1a49f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_7d26c1c69f6843a7bca8eff45b301330","placeholder":"â€‹","style":"IPY_MODEL_d1e61c3c946c4a7387fc645c3cec03e6","tabbable":null,"tooltip":null,"value":"vocab.json:â€‡100%"}},"b9c9b2960739404c939f18ad4b38554f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be0d810060e54fc38ed15c2dce79bec5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4450346f0c748cea5ea485e16740fa2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_e54cdde76522416ebfadd589061c3f0c","placeholder":"â€‹","style":"IPY_MODEL_0762539edd78430caacae16a3bf209d7","tabbable":null,"tooltip":null,"value":"â€‡124/124â€‡[00:00&lt;00:00,â€‡16.2kB/s]"}},"c55b7d411bc54a2587425ef7d726ce86":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_8aedd556af1d41f985441deeaec97292","placeholder":"â€‹","style":"IPY_MODEL_28b73a1708474add8399168a57baf958","tabbable":null,"tooltip":null,"value":"â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡20.4MB/s]"}},"c5c6c96627454513aa70ab1fdac98207":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_752ab28e2da44283a335f94843c07da0","placeholder":"â€‹","style":"IPY_MODEL_3edebc19685841bf9467ec4213803d06","tabbable":null,"tooltip":null,"value":"â€‡762/762â€‡[00:00&lt;00:00,â€‡89.1kB/s]"}},"ca7ef867528a4890b960d8cf1f1ed12e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cbca2a41a48b484bbabfbf4c241257d6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbdc04a7d92b489d940823b8822a9523":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"cda416a18dae47918ab902682c06c783":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75204fcfac51470ea43cf0085e9389a8","IPY_MODEL_085557d00f8440e7a2c84b955951f1e0","IPY_MODEL_fee357f6f4c645fa8e6926bb4ac7bae0"],"layout":"IPY_MODEL_37a5357fd6c34574b7361e962c17d2a5","tabbable":null,"tooltip":null}},"ce55a5a13594453aad44f664099dd930":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fca916986901405dbbd029d7b4a0a77d","IPY_MODEL_aea3325eb678447ca8b9b607fc6fe982","IPY_MODEL_5c1788efbd8546779aed1a3f52b64045"],"layout":"IPY_MODEL_8fb958e31d6843239c9a7f0b48b10936","tabbable":null,"tooltip":null}},"d1e61c3c946c4a7387fc645c3cec03e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"d2ba11375af640aca76e2a7f408d55eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5fcbe242e1b4bfe92919b11c1b1a49f","IPY_MODEL_17208e9c8548494b9d5d1efc611d3e06","IPY_MODEL_48973c20781f4dffa2269edd41565276"],"layout":"IPY_MODEL_cbca2a41a48b484bbabfbf4c241257d6","tabbable":null,"tooltip":null}},"d54680151dea4a89a5edc6426875ebbd":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d787eb4d0cbf478d87634d0a911a08d5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d89b44c9422c49cf93df18cfc3608d12":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"db995b43df7f43b4a4644b17a3864c40":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dba87a6882a04a0aae6162c3319f2b66":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"e30ee52cc7cd4b8e95b0b8b1d03a923e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e54cdde76522416ebfadd589061c3f0c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e56d0554274a4121a02d71b604ae2a6d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea41480edab142d2a6e91c5030353824":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec93d80a857944f98f0dfe4ea90325bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"efb68158971745e9a02d38c5145bc996":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f603b22778664b14a7e6dfdd1bfeb160":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f613418f2a9f48c2a22b4e2c45d88fe6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9b58c66b18646d3a48227b93cd6f685":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_add0878bd0a742fa882bad3d1e5512fb","placeholder":"â€‹","style":"IPY_MODEL_a78b81c47e9a43c18df9d0d3b55bcc22","tabbable":null,"tooltip":null,"value":"â€‡353M/353Mâ€‡[00:01&lt;00:00,â€‡245MB/s]"}},"fca916986901405dbbd029d7b4a0a77d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_5a87bd97cec74f989fb01c7511192290","placeholder":"â€‹","style":"IPY_MODEL_cbdc04a7d92b489d940823b8822a9523","tabbable":null,"tooltip":null,"value":"tokenizer_config.json:â€‡100%"}},"fd294cfc69b6401d8badb78d25d54166":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_518ce5584fbb4a9ca2b674a730020d54","max":352824413.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_3f94719ac38a4bc68195079da4afa167","tabbable":null,"tooltip":null,"value":352824413.0}},"fee357f6f4c645fa8e6926bb4ac7bae0":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_91f17b63ec784a0a980de540afce6209","placeholder":"â€‹","style":"IPY_MODEL_dba87a6882a04a0aae6162c3319f2b66","tabbable":null,"tooltip":null,"value":"â€‡3725/3725â€‡[00:00&lt;00:00,â€‡10615.84â€‡examples/s]"}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}